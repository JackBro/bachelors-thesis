\subsubsection{Experiment: DLL Component Overhead}
\begin{figure}[h]
	\centering
    \includegraphics[width=\textwidth,height=0.45\textheight,keepaspectratio]{Evaluation/experiment2/result.png}
    \caption{Average execution time for sha256 file hashing}
    \label{fig:ex2_result}
\end{figure}
In Experiment 2 the performance impact of the \gls{DLL} component is evaluated. Experiment 2 uses the same hardware and software setup as Experiment 1. As the result of Experiment 1 showed, that running the \gls{DLL} component slowed down the execution of \emph{Google Chrome}, Experiment 2 tries to find the actual reason for that result. Looking at the code, and running time measurements on it leads to the sha256 file hashing slowing down the execution. Figure~\ref{fig:ex2_result} shows the average of ten independent measurements. For file sizes between four kilobyte ($2^{12}$ byte) and one megabyte ($2^{20}$ byte), the needed time is roughly constant around 16 milliseconds ($2^{14}$ microseconds). Increasing the file size further than one megabyte results into increase of time for hashing the file. The graph uses logarithmic scaling with base two one both axis, which give a better comparability of the actual result. Starting at one megabyte, doubling the file size will double the necessary time to create the sha256 hash. Most \glspl{DLL} are rather small (less than one megabyte) and will require constant time for file hashing. However, in contrast to that, some are very large (around 50 megabyte or even larger) and will require with respect to the given file size linearly more time. An example for that can be found in \emph{Google Chrome's} used \glspl{DLL}. \emph{Chrome\_child.dll} with 40 megabyte and \emph{chrome.dll} with 30 megabyte make up most of the time that is spent for hashing during \emph{Chrome's} process creation. As the initial callback function \syscall{PsSetLoadImageNotifyRoutine} is acting synchronous, so is the hashing of files. Therefore, the process is suspended for the whole time that is needed for hashing all \glspl{DLL}. A single process creation is delayed by the sum of the required time for hashing all \glspl{DLL}, which makes up a total of 2905253 microseconds, or 2.9 seconds.

\paragraph{Impact of \gls{DLL} injections}
In case of an actual attack with \gls{DLL} injections, it is interesting to know which performance impact is present for \emph{Google Chrome}. According to Experiment 2, the time required for hashing is
\begin{equation}
t(x) = \min\{2^{14} * 2^{\log_2(x) - 20}, 2^{14}\} \label{eq:one}
\end{equation}
where $x$ is the file size in bytes of the \gls{DLL} and $t(x)$ is the required time in microseconds for calculating the hash. The time cost of (\ref{eq:one}) is scaling linearly with the size $x$ of the \gls{DLL} file. Therefore, especially for larger files it is interesting to know if hashing is required every time the \gls{DLL} is mapped into memory. In the current implementation, hashing occurs only once, if the \gls{DLL} is not on the whitelist. This is due to \emph{Windows} internal \gls{DLL} loading behavior. The result of patching a \gls{DLL} is an invalid executable format. As soon as a second \gls{DLL} load request for the same file is done, the \emph{Windows} kernel will return early with error \syscall{ERROR\_BAD\_EXE\_FORMAT}. This behavior will stay until the file is unloaded from memory which will happen when exiting \emph{Chrome}. In the other case, where the \gls{DLL} is in the whitelist, there is no such way of returning early. The \gls{DLL} file will need to be hashed again if it is not present in the process virtual memory. This is another limitation of the approach using \syscall{PsSetLoadImageNotifyRoutine}.